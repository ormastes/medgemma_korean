{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 0.1: Research Korean Medical Datasets\n",
    "\n",
    "Research and document available datasets for Korean medical LLM training.\n",
    "\n",
    "## Contents\n",
    "1. Korean Medical Datasets\n",
    "2. Korean General Corpus\n",
    "3. Korean Instruction Datasets\n",
    "4. Bilingual Resources\n",
    "5. Dataset Summary and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfApi, list_datasets\n",
    "import pandas as pd\n",
    "\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Korean Medical Datasets\n",
    "\n",
    "### 1.1 KorMedMCQA (Primary Benchmark)\n",
    "\n",
    "**Source**: [sean0042/KorMedMCQA](https://huggingface.co/datasets/sean0042/KorMedMCQA)\n",
    "\n",
    "**Description**: First Korean Medical Multiple-Choice Question Answering benchmark from professional healthcare licensing examinations (2012-2024).\n",
    "\n",
    "**Details**:\n",
    "- 7,469 questions from doctor, nurse, pharmacist, dentist exams\n",
    "- Wide range of medical disciplines\n",
    "- Best model: o1-preview (92.72%), Qwen2.5-72B (78.86%)\n",
    "- Chain of Thought improves performance by up to 4.5%\n",
    "\n",
    "**Paper**: [arXiv:2403.01469](https://arxiv.org/abs/2403.01469)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Explore KorMedMCQA - load just doctor config to save memory\nprint(\"KorMedMCQA Dataset Structure:\")\nprint(\"Available configs: dentist, doctor, nurse, pharm\")\n\ntry:\n    kormedmcqa = load_dataset(\"sean0042/KorMedMCQA\", \"doctor\")\n    print(f\"\\nDoctor config loaded:\")\n    print(kormedmcqa)\n    \n    print(\"\\nSample entry:\")\n    sample = kormedmcqa['train'][0] if 'train' in kormedmcqa else kormedmcqa[list(kormedmcqa.keys())[0]][0]\n    for key, value in sample.items():\n        print(f\"  {key}: {str(value)[:200]}...\" if len(str(value)) > 200 else f\"  {key}: {value}\")\nexcept Exception as e:\n    print(f\"Could not load KorMedMCQA: {e}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dataset statistics for loaded config\nprint(\"Dataset Statistics (doctor config):\")\nif 'kormedmcqa' in dir():\n    for split in kormedmcqa.keys():\n        print(f\"  {split}: {len(kormedmcqa[split])} examples\")\n    print(f\"\\nColumns: {kormedmcqa['train'].column_names if 'train' in kormedmcqa else 'N/A'}\")\n    print(\"\\nNote: Total across all configs (dentist, doctor, nurse, pharm) is ~7,469 examples\")\n    \n    # Clean up memory\n    del kormedmcqa\n    import gc\n    gc.collect()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 KorMedLawQA\n",
    "\n",
    "**Source**: [snuh/KorMedLawQA](https://huggingface.co/datasets/snuh/KorMedLawQA)\n",
    "\n",
    "**Description**: Korean Medical Law QA dataset from Seoul National University Hospital (SNUH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Explore KorMedLawQA - skip if not available\nprint(\"KorMedLawQA Dataset:\")\nprint(\"  Source: snuh/KorMedLawQA\")\nprint(\"  Note: May require authentication or special access\")\nprint(\"  Skipping load to save memory - check manually if needed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Medical Reasoning KorMedMCQA\n",
    "\n",
    "**Source**: [ChuGyouk/medical-reasoning-train-kormedmcqa](https://huggingface.co/datasets/ChuGyouk/medical-reasoning-train-kormedmcqa)\n",
    "\n",
    "**Description**: KorMedMCQA with reasoning chains for Chain-of-Thought training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Explore Medical Reasoning dataset - brief check\nprint(\"Medical Reasoning KorMedMCQA:\")\nprint(\"  Source: ChuGyouk/medical-reasoning-train-kormedmcqa\")\nprint(\"  Description: KorMedMCQA with Chain-of-Thought reasoning\")\nprint(\"  Skipping full load to save memory\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 KBMC (Korean Bio-Medical Corpus for NER)\n",
    "\n",
    "**Source**: [arXiv:2403.16158](https://arxiv.org/abs/2403.16158)\n",
    "\n",
    "**Description**: First open-source Korean medical NER dataset.\n",
    "\n",
    "**Details**:\n",
    "- Entity types: disease name, body part, treatment\n",
    "- BIO format annotations\n",
    "- 20% improvement over general Korean NER datasets\n",
    "- Published at LREC-COLING 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for KBMC on HuggingFace\n",
    "kbmc_datasets = list(api.list_datasets(search=\"KBMC Korean medical\", limit=10))\n",
    "print(\"KBMC related datasets on HuggingFace:\")\n",
    "for ds in kbmc_datasets:\n",
    "    print(f\"  - {ds.id}\")\n",
    "\n",
    "if not kbmc_datasets:\n",
    "    print(\"  No KBMC datasets found on HuggingFace.\")\n",
    "    print(\"  May need to request from paper authors or construct manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Korean General Corpus (for Tokenizer Training)\n",
    "\n",
    "### 2.1 OSCAR Korean\n",
    "\n",
    "**Source**: [oscar-corpus/OSCAR-2301](https://huggingface.co/datasets/oscar-corpus/OSCAR-2301)\n",
    "\n",
    "**Description**: Open Super-large Crawled Aggregated coRpus - multilingual web corpus.\n",
    "\n",
    "**Details**:\n",
    "- Korean subset available (`ko` language code)\n",
    "- Large scale (10GB+)\n",
    "- Research-only license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Explore OSCAR Korean (streaming due to size)\nprint(\"OSCAR-2301 Korean subset:\")\nprint(\"  Source: oscar-corpus/OSCAR-2301\")\nprint(\"  Note: This is a GATED dataset requiring HuggingFace authentication\")\nprint(\"  To access: 1) Login at huggingface.co\")\nprint(\"            2) Accept terms at https://huggingface.co/datasets/oscar-corpus/OSCAR-2301\")\nprint(\"            3) Run: huggingface-cli login\")\nprint(\"\\nAlternative: Use cc100 or other open Korean corpora\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 mC4 Korean\n",
    "\n",
    "**Source**: [mc4](https://huggingface.co/datasets/mc4) (deprecated, use [allenai/c4](https://huggingface.co/datasets/allenai/c4))\n",
    "\n",
    "**Description**: Multilingual colossal cleaned Common Crawl corpus.\n",
    "\n",
    "**Details**:\n",
    "- 108 languages supported\n",
    "- Korean subset available\n",
    "- Very large scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Explore mC4 Korean (streaming)\nprint(\"mC4 Korean subset:\")\nprint(\"  Source: mc4 (ko config)\")\nprint(\"  Note: May also require authentication\")\nprint(\"  Alternative: allenai/c4\")\nprint(\"\\nSkipping load - check access requirements manually\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Korean Pretraining Dataset Collection\n",
    "\n",
    "**Source**: [heegyu/korean-pretraining-dataset](https://huggingface.co/collections/heegyu/korean-pretraining-dataset-65c59136735dd9c8163ec50c)\n",
    "\n",
    "**Description**: Curated collection of Korean pretraining datasets including mC4 + OSCAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for Korean pretraining datasets\n",
    "ko_pretrain_datasets = list(api.list_datasets(search=\"Korean pretraining\", limit=20))\n",
    "print(\"Korean pretraining datasets on HuggingFace:\")\n",
    "for ds in ko_pretrain_datasets:\n",
    "    print(f\"  - {ds.id}: {ds.downloads} downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Korean Wikipedia\n",
    "\n",
    "**Source**: [wikimedia/wikipedia](https://huggingface.co/datasets/wikimedia/wikipedia)\n",
    "\n",
    "**Description**: Wikipedia dumps for multiple languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Explore Korean Wikipedia\nprint(\"Korean Wikipedia:\")\nprint(\"  Source: wikimedia/wikipedia (20231101.ko)\")\n\ntry:\n    wiki_ko = load_dataset(\"wikimedia/wikipedia\", \"20231101.ko\", split=\"train\", streaming=True)\n    \n    print(\"\\nSample entries:\")\n    for i, example in enumerate(wiki_ko):\n        print(f\"\\nSample {i+1}:\")\n        print(f\"  Title: {example.get('title', 'N/A')}\")\n        text_preview = example['text'][:300] if 'text' in example else str(example)[:300]\n        print(f\"  Text (first 300 chars): {text_preview}...\")\n        if i >= 1:\n            break\nexcept Exception as e:\n    print(f\"Could not load Korean Wikipedia: {e}\")\n    print(\"May need to check dataset path or authentication\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Korean Instruction Datasets\n",
    "\n",
    "### 3.1 KoAlpaca\n",
    "\n",
    "**Source**: [beomi/KoAlpaca-v1.1a](https://huggingface.co/datasets/beomi/KoAlpaca-v1.1a)\n",
    "\n",
    "**Description**: Korean instruction-following dataset based on Stanford Alpaca.\n",
    "\n",
    "**Details**:\n",
    "- 21,155 examples\n",
    "- Cost: < $500 to create\n",
    "- Features: instruction, input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Explore KoAlpaca - streaming to save memory\nprint(\"KoAlpaca Dataset:\")\nprint(\"  Source: beomi/KoAlpaca-v1.1a\")\nprint(\"  Size: 21,155 examples\")\nprint(\"  Features: instruction, input, output\")\n\ntry:\n    koalpaca = load_dataset(\"beomi/KoAlpaca-v1.1a\", split=\"train\", streaming=True)\n    print(\"\\nSample entries:\")\n    for i, example in enumerate(koalpaca):\n        print(f\"\\n--- Sample {i+1} ---\")\n        print(f\"Instruction: {example['instruction'][:200]}...\")\n        print(f\"Output: {example['output'][:200]}...\")\n        if i >= 1:\n            break\nexcept Exception as e:\n    print(f\"Could not load: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 KoAlpaca-RealQA\n",
    "\n",
    "**Source**: [beomi/KoAlpaca-RealQA](https://huggingface.co/datasets/beomi/KoAlpaca-RealQA)\n",
    "\n",
    "**Description**: Real Korean user interactions from ChatKoAlpaca service (2023-2024), with GPT-4o generated answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# KoAlpaca-RealQA info\nprint(\"KoAlpaca-RealQA Dataset:\")\nprint(\"  Source: beomi/KoAlpaca-RealQA\")\nprint(\"  Description: Real user interactions with GPT-4o answers\")\nprint(\"  Skipping load to save memory\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Korean Translated Alpaca\n",
    "\n",
    "**Source**: [Bingsu/ko_alpaca_data](https://huggingface.co/datasets/Bingsu/ko_alpaca_data)\n",
    "\n",
    "**Description**: Korean translation of Alpaca data via DeepL API, with GPT-3.5-turbo generated outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ko_alpaca_data info\nprint(\"Bingsu/ko_alpaca_data:\")\nprint(\"  Size: 49,620 examples\")\nprint(\"  Features: instruction, input, output\")\nprint(\"  Description: Korean translation via DeepL API\")\nprint(\"  Skipping load to save memory\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Bilingual Resources\n",
    "\n",
    "### 4.1 UMLS Korean Mappings\n",
    "\n",
    "**Description**: Unified Medical Language System contains Korean translations for medical terminology.\n",
    "\n",
    "**Access**: Requires UMLS license from NLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: UMLS requires license\n",
    "print(\"UMLS Korean Medical Terminology:\")\n",
    "print(\"  - Requires UMLS license from NLM (https://www.nlm.nih.gov/research/umls/)\")\n",
    "print(\"  - Contains Korean translations for medical terms\")\n",
    "print(\"  - Useful for bilingual dictionary construction\")\n",
    "print(\"\\nAlternative: Create custom bilingual medical dictionary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 CCAligned / OPUS Parallel Corpora\n",
    "\n",
    "**Description**: Parallel corpora for English-Korean translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for English-Korean parallel corpora\n",
    "parallel_datasets = list(api.list_datasets(search=\"English Korean parallel translation\", limit=15))\n",
    "print(\"English-Korean parallel corpora on HuggingFace:\")\n",
    "for ds in parallel_datasets:\n",
    "    print(f\"  - {ds.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Dataset Summary and Selection\n",
    "\n",
    "### Selected Datasets for Korean MedGemma Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dataframe\n",
    "dataset_summary = pd.DataFrame([\n",
    "    {\n",
    "        \"Name\": \"KorMedMCQA\",\n",
    "        \"Type\": \"Medical QA\",\n",
    "        \"Size\": \"7,469 QA pairs\",\n",
    "        \"Source\": \"sean0042/KorMedMCQA\",\n",
    "        \"Use\": \"Evaluation + Instruction tuning\",\n",
    "        \"Priority\": \"High\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"Medical Reasoning KorMedMCQA\",\n",
    "        \"Type\": \"Medical QA + CoT\",\n",
    "        \"Size\": \"~7K\",\n",
    "        \"Source\": \"ChuGyouk/medical-reasoning-train-kormedmcqa\",\n",
    "        \"Use\": \"Chain-of-Thought training\",\n",
    "        \"Priority\": \"High\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"KorMedLawQA\",\n",
    "        \"Type\": \"Medical Law QA\",\n",
    "        \"Size\": \"TBD\",\n",
    "        \"Source\": \"snuh/KorMedLawQA\",\n",
    "        \"Use\": \"Domain-specific fine-tuning\",\n",
    "        \"Priority\": \"Medium\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"OSCAR Korean\",\n",
    "        \"Type\": \"General Corpus\",\n",
    "        \"Size\": \"10GB+\",\n",
    "        \"Source\": \"oscar-corpus/OSCAR-2301 (ko)\",\n",
    "        \"Use\": \"Tokenizer training\",\n",
    "        \"Priority\": \"High\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"Korean Wikipedia\",\n",
    "        \"Type\": \"Encyclopedia\",\n",
    "        \"Size\": \"~100M tokens\",\n",
    "        \"Source\": \"wikimedia/wikipedia (ko)\",\n",
    "        \"Use\": \"Language modeling + Medical filtering\",\n",
    "        \"Priority\": \"High\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"KoAlpaca-v1.1a\",\n",
    "        \"Type\": \"Instruction\",\n",
    "        \"Size\": \"21,155\",\n",
    "        \"Source\": \"beomi/KoAlpaca-v1.1a\",\n",
    "        \"Use\": \"General instruction tuning\",\n",
    "        \"Priority\": \"Medium\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"KoAlpaca-RealQA\",\n",
    "        \"Type\": \"Real User QA\",\n",
    "        \"Size\": \"TBD\",\n",
    "        \"Source\": \"beomi/KoAlpaca-RealQA\",\n",
    "        \"Use\": \"Real-world instruction tuning\",\n",
    "        \"Priority\": \"Medium\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"ko_alpaca_data\",\n",
    "        \"Type\": \"Instruction (translated)\",\n",
    "        \"Size\": \"49,620\",\n",
    "        \"Source\": \"Bingsu/ko_alpaca_data\",\n",
    "        \"Use\": \"Instruction tuning\",\n",
    "        \"Priority\": \"Medium\",\n",
    "    },\n",
    "])\n",
    "\n",
    "print(\"Dataset Summary for Korean MedGemma:\")\n",
    "print(\"=\" * 100)\n",
    "print(dataset_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset summary\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "\n",
    "dataset_config = {\n",
    "    \"medical_datasets\": [\n",
    "        {\n",
    "            \"name\": \"KorMedMCQA\",\n",
    "            \"hf_path\": \"sean0042/KorMedMCQA\",\n",
    "            \"use\": [\"evaluation\", \"instruction_tuning\"],\n",
    "            \"priority\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Medical Reasoning KorMedMCQA\",\n",
    "            \"hf_path\": \"ChuGyouk/medical-reasoning-train-kormedmcqa\",\n",
    "            \"use\": [\"chain_of_thought\"],\n",
    "            \"priority\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"KorMedLawQA\",\n",
    "            \"hf_path\": \"snuh/KorMedLawQA\",\n",
    "            \"use\": [\"domain_specific\"],\n",
    "            \"priority\": \"medium\",\n",
    "        },\n",
    "    ],\n",
    "    \"general_corpus\": [\n",
    "        {\n",
    "            \"name\": \"OSCAR Korean\",\n",
    "            \"hf_path\": \"oscar-corpus/OSCAR-2301\",\n",
    "            \"config\": \"ko\",\n",
    "            \"use\": [\"tokenizer_training\", \"language_modeling\"],\n",
    "            \"priority\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Korean Wikipedia\",\n",
    "            \"hf_path\": \"wikimedia/wikipedia\",\n",
    "            \"config\": \"20231101.ko\",\n",
    "            \"use\": [\"language_modeling\", \"medical_filtering\"],\n",
    "            \"priority\": \"high\",\n",
    "        },\n",
    "    ],\n",
    "    \"instruction_datasets\": [\n",
    "        {\n",
    "            \"name\": \"KoAlpaca-v1.1a\",\n",
    "            \"hf_path\": \"beomi/KoAlpaca-v1.1a\",\n",
    "            \"use\": [\"instruction_tuning\"],\n",
    "            \"priority\": \"medium\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"KoAlpaca-RealQA\",\n",
    "            \"hf_path\": \"beomi/KoAlpaca-RealQA\",\n",
    "            \"use\": [\"instruction_tuning\"],\n",
    "            \"priority\": \"medium\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ko_alpaca_data\",\n",
    "            \"hf_path\": \"Bingsu/ko_alpaca_data\",\n",
    "            \"use\": [\"instruction_tuning\"],\n",
    "            \"priority\": \"medium\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "with open(\"../data/dataset_config.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dataset_config, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Dataset config saved to ../data/dataset_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Plan\n",
    "\n",
    "| Phase | Datasets | Purpose | Target Size |\n",
    "|-------|----------|---------|-------------|\n",
    "| Tokenizer Training | OSCAR Korean | Learn Korean subwords | 10GB |\n",
    "| Stage 1-5 (Embeddings) | OSCAR + Wikipedia (medical) | Korean language modeling | 500M-1B tokens |\n",
    "| Stage 6-7 (LoRA) | Mixed Korean + 10% English | Full adaptation | 1-2B tokens |\n",
    "| Instruction Tuning | KorMedMCQA + KoAlpaca | Medical QA + General | 100K examples |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Dataset Research Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Run 02_collect_korean_medical.ipynb to download medical datasets\")\n",
    "print(\"  2. Run 03_collect_bilingual_dict.ipynb to create bilingual dictionary\")\n",
    "print(\"  3. Run 04_preprocess_data.ipynb to prepare training data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
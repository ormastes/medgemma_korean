{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ae2c08",
   "metadata": {
    "papermill": {
     "duration": 0.005196,
     "end_time": "2025-12-05T09:27:18.328685",
     "exception": false,
     "start_time": "2025-12-05T09:27:18.323489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Phase 0.2: Collect Korean Medical Datasets\n",
    "\n",
    "Download and prepare Korean medical datasets for training.\n",
    "\n",
    "## Contents\n",
    "1. Setup and GPU Configuration\n",
    "2. Download KorMedMCQA\n",
    "3. Download Medical Reasoning Dataset\n",
    "4. Download KorMedLawQA\n",
    "5. Filter Medical Content from Wikipedia\n",
    "6. Save All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d506fed0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:18.339210Z",
     "iopub.status.busy": "2025-12-05T09:27:18.339010Z",
     "iopub.status.idle": "2025-12-05T09:27:20.529706Z",
     "shell.execute_reply": "2025-12-05T09:27:20.528637Z"
    },
    "papermill": {
     "duration": 2.197187,
     "end_time": "2025-12-05T09:27:20.530525",
     "exception": false,
     "start_time": "2025-12-05T09:27:18.333338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA RTX A6000\n",
      "Memory: 47.4 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ormastes/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: ../data\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# GPU setup\n",
    "from config.gpu_utils import setup_gpu, print_memory_usage\n",
    "device = setup_gpu()\n",
    "\n",
    "# Imports\n",
    "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "from huggingface_hub import HfApi\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Create data directories\n",
    "DATA_DIR = \"../data\"\n",
    "RAW_DIR = f\"{DATA_DIR}/raw\"\n",
    "PROCESSED_DIR = f\"{DATA_DIR}/processed\"\n",
    "\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617c6fc",
   "metadata": {
    "papermill": {
     "duration": 0.011441,
     "end_time": "2025-12-05T09:27:20.547282",
     "exception": false,
     "start_time": "2025-12-05T09:27:20.535841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 1. Download KorMedMCQA (Primary Medical Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232cddff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:20.558321Z",
     "iopub.status.busy": "2025-12-05T09:27:20.558023Z",
     "iopub.status.idle": "2025-12-05T09:27:23.294044Z",
     "shell.execute_reply": "2025-12-05T09:27:23.292884Z"
    },
    "papermill": {
     "duration": 2.742771,
     "end_time": "2025-12-05T09:27:23.294944",
     "exception": false,
     "start_time": "2025-12-05T09:27:20.552173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading KorMedMCQA (doctor config only to save memory)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded doctor config: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['subject', 'year', 'period', 'q_number', 'question', 'A', 'B', 'C', 'D', 'E', 'answer', 'cot'],\n",
      "        num_rows: 1890\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['subject', 'year', 'period', 'q_number', 'question', 'A', 'B', 'C', 'D', 'E', 'answer', 'cot'],\n",
      "        num_rows: 164\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['subject', 'year', 'period', 'q_number', 'question', 'A', 'B', 'C', 'D', 'E', 'answer', 'cot'],\n",
      "        num_rows: 435\n",
      "    })\n",
      "    fewshot: Dataset({\n",
      "        features: ['subject', 'year', 'period', 'q_number', 'question', 'A', 'B', 'C', 'D', 'E', 'answer', 'cot'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "})\n",
      "\n",
      "Sample entry:\n",
      "  subject: doctor\n",
      "  year: 2012\n",
      "  period: 1\n",
      "  q_number: 1\n",
      "  question: 항문압 측정 검사에서 항문 압력이 증가하는 경우는?\n",
      "  A: 직장질루(rectovaginal fistula)\n",
      "  B: 항문열창(anal fissure)\n",
      "  C: 대변실금(fecal incontinence)\n",
      "  D: 대변메막힘(fecal impaction)\n",
      "  E: 직장탈출증(rectal prolapse)\n",
      "  answer: 2\n",
      "  cot: \n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading KorMedMCQA (doctor config only to save memory)...\")\n",
    "\n",
    "# Load just doctor config to save memory\n",
    "try:\n",
    "    kormedmcqa_doctor = load_dataset(\"sean0042/KorMedMCQA\", \"doctor\")\n",
    "    print(f\"Loaded doctor config: {kormedmcqa_doctor}\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(f\"\\nSample entry:\")\n",
    "    split = 'train' if 'train' in kormedmcqa_doctor else list(kormedmcqa_doctor.keys())[0]\n",
    "    sample = kormedmcqa_doctor[split][0]\n",
    "    for key, value in sample.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    kormedmcqa_all = {'doctor': kormedmcqa_doctor}\n",
    "except Exception as e:\n",
    "    print(f\"Error loading KorMedMCQA: {e}\")\n",
    "    kormedmcqa_all = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da7ce35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:23.307889Z",
     "iopub.status.busy": "2025-12-05T09:27:23.307618Z",
     "iopub.status.idle": "2025-12-05T09:27:23.417803Z",
     "shell.execute_reply": "2025-12-05T09:27:23.416793Z"
    },
    "papermill": {
     "duration": 0.117234,
     "end_time": "2025-12-05T09:27:23.418760",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.301526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics:\n",
      "  doctor/train: 1890 examples\n",
      "  doctor/dev: 164 examples\n",
      "  doctor/test: 435 examples\n",
      "  doctor/fewshot: 5 examples\n"
     ]
    }
   ],
   "source": [
    "# Quick statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "if kormedmcqa_all:\n",
    "    for config, ds in kormedmcqa_all.items():\n",
    "        for split in ds.keys():\n",
    "            print(f\"  {config}/{split}: {len(ds[split])} examples\")\n",
    "    \n",
    "    # Clean up to save memory\n",
    "    import gc\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0644ee89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:23.430407Z",
     "iopub.status.busy": "2025-12-05T09:27:23.430239Z",
     "iopub.status.idle": "2025-12-05T09:27:23.726587Z",
     "shell.execute_reply": "2025-12-05T09:27:23.725669Z"
    },
    "papermill": {
     "duration": 0.303323,
     "end_time": "2025-12-05T09:27:23.727561",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.424238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Saving the dataset (0/1 shards):   0%|          | 0/1890 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Saving the dataset (1/1 shards): 100%|██████████| 1890/1890 [00:00<00:00, 231134.93 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Saving the dataset (1/1 shards): 100%|██████████| 1890/1890 [00:00<00:00, 210243.59 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Saving the dataset (0/1 shards):   0%|          | 0/604 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Saving the dataset (1/1 shards): 100%|██████████| 604/604 [00:00<00:00, 97264.82 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Saving the dataset (1/1 shards): 100%|██████████| 604/604 [00:00<00:00, 84645.65 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined KorMedMCQA to ../data/raw/kormedmcqa\n",
      "  Train: 1890, Test: 604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save KorMedMCQA (all configs combined)\n",
    "kormedmcqa_path = f\"{RAW_DIR}/kormedmcqa\"\n",
    "\n",
    "# Combine all configs into one DatasetDict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "combined_train = []\n",
    "combined_test = []\n",
    "\n",
    "for config, ds in kormedmcqa_all.items():\n",
    "    for split in ds.keys():\n",
    "        for item in ds[split]:\n",
    "            item_dict = dict(item)\n",
    "            item_dict['exam_type'] = config  # Add exam type as column\n",
    "            if 'train' in split.lower():\n",
    "                combined_train.append(item_dict)\n",
    "            else:\n",
    "                combined_test.append(item_dict)\n",
    "\n",
    "# Create combined dataset\n",
    "combined_ds = DatasetDict({\n",
    "    'train': Dataset.from_list(combined_train) if combined_train else Dataset.from_list([]),\n",
    "    'test': Dataset.from_list(combined_test) if combined_test else Dataset.from_list([]),\n",
    "})\n",
    "\n",
    "combined_ds.save_to_disk(kormedmcqa_path)\n",
    "print(f\"Saved combined KorMedMCQA to {kormedmcqa_path}\")\n",
    "print(f\"  Train: {len(combined_ds['train'])}, Test: {len(combined_ds['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed429499",
   "metadata": {
    "papermill": {
     "duration": 0.005655,
     "end_time": "2025-12-05T09:27:23.739529",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.733874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 2. Download Medical Reasoning Dataset (Chain-of-Thought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc175b34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:23.751958Z",
     "iopub.status.busy": "2025-12-05T09:27:23.751789Z",
     "iopub.status.idle": "2025-12-05T09:27:23.755551Z",
     "shell.execute_reply": "2025-12-05T09:27:23.754689Z"
    },
    "papermill": {
     "duration": 0.011608,
     "end_time": "2025-12-05T09:27:23.756787",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.745179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical Reasoning KorMedMCQA:\n",
      "  Source: ChuGyouk/medical-reasoning-train-kormedmcqa\n",
      "  Skipping to save memory - can be loaded later\n"
     ]
    }
   ],
   "source": [
    "print(\"Medical Reasoning KorMedMCQA:\")\n",
    "print(\"  Source: ChuGyouk/medical-reasoning-train-kormedmcqa\")\n",
    "print(\"  Skipping to save memory - can be loaded later\")\n",
    "med_reasoning = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ffed01",
   "metadata": {
    "papermill": {
     "duration": 0.005995,
     "end_time": "2025-12-05T09:27:23.769155",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.763160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 3. Download KorMedLawQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d5903d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:23.781221Z",
     "iopub.status.busy": "2025-12-05T09:27:23.781062Z",
     "iopub.status.idle": "2025-12-05T09:27:23.784846Z",
     "shell.execute_reply": "2025-12-05T09:27:23.783924Z"
    },
    "papermill": {
     "duration": 0.010313,
     "end_time": "2025-12-05T09:27:23.785462",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.775149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KorMedLawQA:\n",
      "  Source: snuh/KorMedLawQA\n",
      "  Skipping to save memory - can be loaded later\n"
     ]
    }
   ],
   "source": [
    "print(\"KorMedLawQA:\")\n",
    "print(\"  Source: snuh/KorMedLawQA\")\n",
    "print(\"  Skipping to save memory - can be loaded later\")\n",
    "kormedlawqa = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a7d3c",
   "metadata": {
    "papermill": {
     "duration": 0.003726,
     "end_time": "2025-12-05T09:27:23.793115",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.789389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 4. Filter Medical Content from Korean Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349f575d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:23.801307Z",
     "iopub.status.busy": "2025-12-05T09:27:23.801073Z",
     "iopub.status.idle": "2025-12-05T09:27:23.809145Z",
     "shell.execute_reply": "2025-12-05T09:27:23.808082Z"
    },
    "papermill": {
     "duration": 0.013328,
     "end_time": "2025-12-05T09:27:23.809859",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.796531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical keywords: 74\n"
     ]
    }
   ],
   "source": [
    "# Medical keywords for filtering\n",
    "MEDICAL_KEYWORDS_KO = [\n",
    "    # Diseases\n",
    "    \"질병\", \"질환\", \"증후군\", \"암\", \"종양\", \"감염\", \"바이러스\", \"세균\",\n",
    "    \"당뇨\", \"고혈압\", \"뇌졸중\", \"심장\", \"폐렴\", \"간염\", \"신장\",\n",
    "    \n",
    "    # Medical practice\n",
    "    \"의학\", \"의료\", \"치료\", \"진단\", \"수술\", \"처방\", \"투약\", \"주사\",\n",
    "    \"병원\", \"의사\", \"간호사\", \"환자\", \"약사\", \"약물\", \"약품\",\n",
    "    \n",
    "    # Body parts\n",
    "    \"심장\", \"폐\", \"간\", \"신장\", \"위장\", \"뇌\", \"혈관\", \"뼈\", \"근육\",\n",
    "    \"피부\", \"눈\", \"귀\", \"코\", \"목\", \"장기\",\n",
    "    \n",
    "    # Symptoms\n",
    "    \"증상\", \"통증\", \"발열\", \"기침\", \"두통\", \"피로\", \"구토\", \"설사\",\n",
    "    \"염증\", \"부종\", \"출혈\",\n",
    "    \n",
    "    # Medical specialties\n",
    "    \"내과\", \"외과\", \"소아과\", \"산부인과\", \"정신과\", \"피부과\", \"안과\",\n",
    "    \"이비인후과\", \"치과\", \"응급의학\", \"마취과\",\n",
    "    \n",
    "    # Health\n",
    "    \"건강\", \"면역\", \"예방\", \"백신\", \"검진\", \"혈액\", \"호르몬\",\n",
    "]\n",
    "\n",
    "def is_medical_article(text, title=\"\"):\n",
    "    \"\"\"Check if article is medical-related\"\"\"\n",
    "    combined = (title + \" \" + text).lower()\n",
    "    \n",
    "    # Count keyword matches\n",
    "    matches = sum(1 for kw in MEDICAL_KEYWORDS_KO if kw in combined)\n",
    "    \n",
    "    # Require at least 2 keyword matches\n",
    "    return matches >= 2\n",
    "\n",
    "print(f\"Medical keywords: {len(MEDICAL_KEYWORDS_KO)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad7f6c92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:23.818878Z",
     "iopub.status.busy": "2025-12-05T09:27:23.818611Z",
     "iopub.status.idle": "2025-12-05T09:27:23.823495Z",
     "shell.execute_reply": "2025-12-05T09:27:23.822443Z"
    },
    "papermill": {
     "duration": 0.010375,
     "end_time": "2025-12-05T09:27:23.824216",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.813841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical Wikipedia filtering:\n",
      "  Skipping full Wikipedia scan to save memory\n",
      "  Will use smaller sample for demo\n",
      "\n",
      "Medical articles placeholder: 0\n"
     ]
    }
   ],
   "source": [
    "# Skip Wikipedia filtering for now - use smaller sample\n",
    "print(\"Medical Wikipedia filtering:\")\n",
    "print(\"  Skipping full Wikipedia scan to save memory\")\n",
    "print(\"  Will use smaller sample for demo\")\n",
    "\n",
    "medical_articles = []\n",
    "print(f\"\\nMedical articles placeholder: {len(medical_articles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40db5d5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:23.833660Z",
     "iopub.status.busy": "2025-12-05T09:27:23.833356Z",
     "iopub.status.idle": "2025-12-05T09:27:23.837678Z",
     "shell.execute_reply": "2025-12-05T09:27:23.836676Z"
    },
    "papermill": {
     "duration": 0.010064,
     "end_time": "2025-12-05T09:27:23.838385",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.828321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample medical articles: (skipped)\n",
      "  Will be collected in full training run\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for medical articles\n",
    "print(\"Sample medical articles: (skipped)\")\n",
    "print(\"  Will be collected in full training run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d42f79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:23.847429Z",
     "iopub.status.busy": "2025-12-05T09:27:23.847153Z",
     "iopub.status.idle": "2025-12-05T09:27:23.851380Z",
     "shell.execute_reply": "2025-12-05T09:27:23.850313Z"
    },
    "papermill": {
     "duration": 0.009546,
     "end_time": "2025-12-05T09:27:23.852079",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.842533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical Wikipedia saving: skipped\n"
     ]
    }
   ],
   "source": [
    "# Skip saving medical Wikipedia for now\n",
    "print(\"Medical Wikipedia saving: skipped\")\n",
    "wiki_medical = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4c0af",
   "metadata": {
    "papermill": {
     "duration": 0.003724,
     "end_time": "2025-12-05T09:27:23.859901",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.856177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 5. Download General Korean Corpus (for Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa29a93d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:23.868960Z",
     "iopub.status.busy": "2025-12-05T09:27:23.868695Z",
     "iopub.status.idle": "2025-12-05T09:27:23.873899Z",
     "shell.execute_reply": "2025-12-05T09:27:23.872875Z"
    },
    "papermill": {
     "duration": 0.011042,
     "end_time": "2025-12-05T09:27:23.874622",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.863580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSCAR Korean corpus:\n",
      "  Note: OSCAR-2301 is a GATED dataset requiring HuggingFace authentication\n",
      "  To access:\n",
      "    1) Accept terms at https://huggingface.co/datasets/oscar-corpus/OSCAR-2301\n",
      "    2) Run: huggingface-cli login\n",
      "\n",
      "  Skipping OSCAR download for now.\n",
      "  Alternative: Use Korean Wikipedia for tokenizer training corpus\n"
     ]
    }
   ],
   "source": [
    "# Skip OSCAR for now - requires authentication\n",
    "print(\"OSCAR Korean corpus:\")\n",
    "print(\"  Note: OSCAR-2301 is a GATED dataset requiring HuggingFace authentication\")\n",
    "print(\"  To access:\")\n",
    "print(\"    1) Accept terms at https://huggingface.co/datasets/oscar-corpus/OSCAR-2301\")\n",
    "print(\"    2) Run: huggingface-cli login\")\n",
    "print(\"\\n  Skipping OSCAR download for now.\")\n",
    "print(\"  Alternative: Use Korean Wikipedia for tokenizer training corpus\")\n",
    "\n",
    "# Create placeholder\n",
    "tokenizer_corpus = []\n",
    "total_chars = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbd1b57a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:23.883877Z",
     "iopub.status.busy": "2025-12-05T09:27:23.883604Z",
     "iopub.status.idle": "2025-12-05T09:27:41.074694Z",
     "shell.execute_reply": "2025-12-05T09:27:41.073570Z"
    },
    "papermill": {
     "duration": 17.196757,
     "end_time": "2025-12-05T09:27:41.075545",
     "exception": false,
     "start_time": "2025-12-05T09:27:23.878788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating small sample corpus for tokenizer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 10000 articles, 28.3MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 30000 articles, 75.2MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 40000 articles, 95.0MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collected 43566 articles, 104.9MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved! File size: 0.216GB\n"
     ]
    }
   ],
   "source": [
    "# Create small sample corpus for tokenizer testing\n",
    "print(\"Creating small sample corpus for tokenizer...\")\n",
    "\n",
    "wiki_corpus_path = f\"{RAW_DIR}/korean_corpus_for_tokenizer.txt\"\n",
    "\n",
    "# Just collect a small sample (100MB) for testing\n",
    "try:\n",
    "    wiki_ko_stream = load_dataset(\"wikimedia/wikipedia\", \"20231101.ko\", split=\"train\", streaming=True)\n",
    "    \n",
    "    tokenizer_corpus = []\n",
    "    total_chars = 0\n",
    "    target_chars = 100 * 1024 * 1024  # 100MB for demo\n",
    "    \n",
    "    for i, article in enumerate(wiki_ko_stream):\n",
    "        text = article.get(\"text\", \"\")\n",
    "        if len(text) < 100:\n",
    "            continue\n",
    "        \n",
    "        tokenizer_corpus.append(text)\n",
    "        total_chars += len(text)\n",
    "        \n",
    "        if total_chars >= target_chars:\n",
    "            break\n",
    "        \n",
    "        if i % 10000 == 0 and i > 0:\n",
    "            print(f\"  Processed {i} articles, {total_chars / 1e6:.1f}MB\")\n",
    "    \n",
    "    print(f\"\\nCollected {len(tokenizer_corpus)} articles, {total_chars / 1e6:.1f}MB\")\n",
    "    \n",
    "    # Save\n",
    "    with open(wiki_corpus_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for text in tokenizer_corpus:\n",
    "            text = re.sub(r'\\s+', ' ', text).strip()\n",
    "            if text:\n",
    "                f.write(text + \"\\n\")\n",
    "    \n",
    "    file_size = os.path.getsize(wiki_corpus_path) / (1024**3)\n",
    "    print(f\"Saved! File size: {file_size:.3f}GB\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error collecting corpus: {e}\")\n",
    "    tokenizer_corpus = []\n",
    "    file_size = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3de866",
   "metadata": {
    "papermill": {
     "duration": 0.007041,
     "end_time": "2025-12-05T09:27:41.090219",
     "exception": false,
     "start_time": "2025-12-05T09:27:41.083178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 6. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c60cb3c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:41.106214Z",
     "iopub.status.busy": "2025-12-05T09:27:41.106034Z",
     "iopub.status.idle": "2025-12-05T09:27:41.112580Z",
     "shell.execute_reply": "2025-12-05T09:27:41.111656Z"
    },
    "papermill": {
     "duration": 0.016312,
     "end_time": "2025-12-05T09:27:41.113743",
     "exception": false,
     "start_time": "2025-12-05T09:27:41.097431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Data Collection Summary\n",
      "============================================================\n",
      "{\n",
      "  \"medical\": {\n",
      "    \"kormedmcqa\": {\n",
      "      \"path\": \"../data/raw/kormedmcqa\",\n",
      "      \"size\": 2494,\n",
      "      \"type\": \"QA\"\n",
      "    }\n",
      "  },\n",
      "  \"general_corpus\": {\n",
      "    \"tokenizer_corpus\": {\n",
      "      \"path\": \"../data/raw/korean_corpus_for_tokenizer.txt\",\n",
      "      \"size_gb\": 0.2163737677037716,\n",
      "      \"num_texts\": 43566\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create summary of collected data\n",
    "collected_datasets = {\n",
    "    \"medical\": {\n",
    "        \"kormedmcqa\": {\n",
    "            \"path\": f\"{RAW_DIR}/kormedmcqa\",\n",
    "            \"size\": len(combined_ds.get('train', [])) + len(combined_ds.get('test', [])),\n",
    "            \"type\": \"QA\",\n",
    "        },\n",
    "    },\n",
    "    \"general_corpus\": {},\n",
    "}\n",
    "\n",
    "# Add tokenizer corpus if we collected it\n",
    "if tokenizer_corpus:\n",
    "    collected_datasets[\"general_corpus\"][\"tokenizer_corpus\"] = {\n",
    "        \"path\": wiki_corpus_path,\n",
    "        \"size_gb\": file_size,\n",
    "        \"num_texts\": len(tokenizer_corpus),\n",
    "    }\n",
    "\n",
    "# Add optional datasets\n",
    "if 'med_reasoning' in dir() and med_reasoning:\n",
    "    collected_datasets[\"medical\"][\"medical_reasoning\"] = {\n",
    "        \"path\": f\"{RAW_DIR}/medical_reasoning_kormedmcqa\",\n",
    "        \"type\": \"QA + CoT\",\n",
    "    }\n",
    "\n",
    "if 'kormedlawqa' in dir() and kormedlawqa:\n",
    "    collected_datasets[\"medical\"][\"kormedlawqa\"] = {\n",
    "        \"path\": f\"{RAW_DIR}/kormedlawqa\",\n",
    "        \"type\": \"Medical Law QA\",\n",
    "    }\n",
    "\n",
    "if 'medical_articles' in dir() and medical_articles:\n",
    "    collected_datasets[\"medical\"][\"wiki_medical_ko\"] = {\n",
    "        \"path\": f\"{RAW_DIR}/wiki_medical_ko\",\n",
    "        \"size\": len(medical_articles),\n",
    "        \"type\": \"Medical Wikipedia\",\n",
    "    }\n",
    "\n",
    "# Save summary\n",
    "with open(f\"{DATA_DIR}/collected_datasets.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(collected_datasets, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Data Collection Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(json.dumps(collected_datasets, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "391419d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T09:27:41.129576Z",
     "iopub.status.busy": "2025-12-05T09:27:41.129424Z",
     "iopub.status.idle": "2025-12-05T09:27:41.133314Z",
     "shell.execute_reply": "2025-12-05T09:27:41.132431Z"
    },
    "papermill": {
     "duration": 0.013493,
     "end_time": "2025-12-05T09:27:41.134670",
     "exception": false,
     "start_time": "2025-12-05T09:27:41.121177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Korean Medical Data Collection Complete!\n",
      "============================================================\n",
      "\n",
      "Data saved to: ../data/raw\n",
      "\n",
      "Next steps:\n",
      "  1. Run 03_collect_bilingual_dict.ipynb to create bilingual dictionary\n",
      "  2. Run 04_preprocess_data.ipynb to prepare training data\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Korean Medical Data Collection Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nData saved to: {RAW_DIR}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Run 03_collect_bilingual_dict.ipynb to create bilingual dictionary\")\n",
    "print(\"  2. Run 04_preprocess_data.ipynb to prepare training data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.741116,
   "end_time": "2025-12-05T09:27:42.161650",
   "environment_variables": {},
   "exception": null,
   "input_path": "02_collect_korean_medical.ipynb",
   "output_path": "02_collect_korean_medical_output.ipynb",
   "parameters": {},
   "start_time": "2025-12-05T09:27:17.420534",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
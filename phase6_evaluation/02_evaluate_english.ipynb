{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Phase 5.2: Evaluate English Medical Retention\n",
    "\n",
    "Check that the model retains English medical capabilities (no catastrophic forgetting).\n",
    "\n",
    "## Contents\n",
    "1. Setup\n",
    "2. Load Models (Korean-adapted and Original)\n",
    "3. Evaluate on English Medical QA\n",
    "4. Compare Results\n",
    "5. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# GPU setup\n",
    "from config.gpu_utils import setup_gpu, print_memory_usage, clear_memory\n",
    "device = setup_gpu()\n",
    "\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# Directories\n# Primary: Use instruction-tuned model\nKOREAN_MODEL_DIR = \"../models/instruction_tuned\"\n\n# Alternative: Use expanded model directly\n# KOREAN_MODEL_DIR = \"../models/final/korean_medgemma_expanded\"\n\n# Original MedGemma for comparison (if available)\nORIGINAL_MODEL = \"../models/medgemma-4b-it\"  # or \"google/medgemma-4b-it\"\n\nRESULTS_DIR = \"../results\"\n\nos.makedirs(RESULTS_DIR, exist_ok=True)\n\nprint(f\"Korean model: {KOREAN_MODEL_DIR}\")\nprint(f\"Original model: {ORIGINAL_MODEL}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. English Medical Test Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample English medical questions for retention testing\n",
    "english_medical_questions = [\n",
    "    {\n",
    "        \"question\": \"A 45-year-old patient presents with chest pain radiating to the left arm, sweating, and shortness of breath. What is the most likely diagnosis?\",\n",
    "        \"choices\": [\"A. Gastroesophageal reflux\", \"B. Acute myocardial infarction\", \"C. Panic attack\", \"D. Pneumonia\", \"E. Costochondritis\"],\n",
    "        \"answer\": \"B\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which medication is considered first-line treatment for Type 2 Diabetes Mellitus?\",\n",
    "        \"choices\": [\"A. Insulin glargine\", \"B. Metformin\", \"C. Glipizide\", \"D. Pioglitazone\", \"E. Sitagliptin\"],\n",
    "        \"answer\": \"B\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the most common cause of community-acquired pneumonia in adults?\",\n",
    "        \"choices\": [\"A. Haemophilus influenzae\", \"B. Staphylococcus aureus\", \"C. Streptococcus pneumoniae\", \"D. Klebsiella pneumoniae\", \"E. Mycoplasma pneumoniae\"],\n",
    "        \"answer\": \"C\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"A patient with hypertension should avoid which of the following?\",\n",
    "        \"choices\": [\"A. Regular exercise\", \"B. High sodium diet\", \"C. Weight management\", \"D. Stress reduction\", \"E. Regular blood pressure monitoring\"],\n",
    "        \"answer\": \"B\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which symptom is NOT typically associated with hyperthyroidism?\",\n",
    "        \"choices\": [\"A. Weight loss\", \"B. Heat intolerance\", \"C. Bradycardia\", \"D. Tremor\", \"E. Anxiety\"],\n",
    "        \"answer\": \"C\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the gold standard for diagnosing peptic ulcer disease?\",\n",
    "        \"choices\": [\"A. Barium swallow\", \"B. CT scan\", \"C. Upper GI endoscopy\", \"D. Ultrasound\", \"E. Blood test\"],\n",
    "        \"answer\": \"C\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which vaccine is recommended annually for adults over 65?\",\n",
    "        \"choices\": [\"A. HPV vaccine\", \"B. MMR vaccine\", \"C. Influenza vaccine\", \"D. Hepatitis B vaccine\", \"E. Varicella vaccine\"],\n",
    "        \"answer\": \"C\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"A patient presents with sudden onset of severe headache, neck stiffness, and photophobia. What should be ruled out first?\",\n",
    "        \"choices\": [\"A. Migraine\", \"B. Tension headache\", \"C. Subarachnoid hemorrhage\", \"D. Cluster headache\", \"E. Sinusitis\"],\n",
    "        \"answer\": \"C\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"Prepared {len(english_medical_questions)} English medical questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Korean-Adapted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Korean-adapted model\n",
    "print(\"Loading Korean-adapted model...\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "korean_model = AutoModelForCausalLM.from_pretrained(\n",
    "    KOREAN_MODEL_DIR,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "korean_tokenizer = AutoTokenizer.from_pretrained(KOREAN_MODEL_DIR)\n",
    "\n",
    "if korean_tokenizer.pad_token is None:\n",
    "    korean_tokenizer.pad_token = korean_tokenizer.eos_token\n",
    "\n",
    "korean_model.eval()\n",
    "\n",
    "print(\"Korean model loaded!\")\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Evaluate Korean Model on English Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_english_prompt(question_data):\n",
    "    \"\"\"Create prompt for English medical question\"\"\"\n",
    "    \n",
    "    question = question_data[\"question\"]\n",
    "    choices = \"\\n\".join(question_data[\"choices\"])\n",
    "    \n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "You are a medical AI assistant. Provide accurate and helpful medical information.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "Answer the following medical question. Respond with only the letter of the correct answer (A, B, C, D, or E).\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Choices:\n",
    "{choices}\n",
    "\n",
    "Answer:\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(response):\n",
    "    \"\"\"Extract answer letter from response\"\"\"\n",
    "    response = response.strip().upper()\n",
    "    \n",
    "    for letter in ['A', 'B', 'C', 'D', 'E']:\n",
    "        if response.startswith(letter):\n",
    "            return letter\n",
    "        if letter in response[:10]:\n",
    "            return letter\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, questions, model_name=\"Model\"):\n",
    "    \"\"\"Evaluate model on English medical questions\"\"\"\n",
    "    \n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    for q in tqdm(questions, desc=f\"Evaluating {model_name}\"):\n",
    "        prompt = create_english_prompt(q)\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=10,\n",
    "                temperature=0.1,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "            )\n",
    "        \n",
    "        response = tokenizer.decode(\n",
    "            outputs[0][inputs[\"input_ids\"].shape[1]:],\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        predicted = extract_answer(response)\n",
    "        is_correct = predicted == q[\"answer\"]\n",
    "        \n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "        \n",
    "        results.append({\n",
    "            \"question\": q[\"question\"],\n",
    "            \"predicted\": predicted,\n",
    "            \"correct\": q[\"answer\"],\n",
    "            \"is_correct\": is_correct,\n",
    "            \"response\": response,\n",
    "        })\n",
    "    \n",
    "    accuracy = correct / len(questions) * 100\n",
    "    return accuracy, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Korean-adapted model\n",
    "print(\"\\nEvaluating Korean-adapted model on English medical questions...\")\n",
    "\n",
    "korean_accuracy, korean_results = evaluate_model(\n",
    "    korean_model, \n",
    "    korean_tokenizer, \n",
    "    english_medical_questions,\n",
    "    \"Korean MedGemma\"\n",
    ")\n",
    "\n",
    "print(f\"\\nKorean-adapted model accuracy: {korean_accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "print(\"\\nEnglish Medical Question Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, r in enumerate(korean_results):\n",
    "    status = \"✓\" if r[\"is_correct\"] else \"✗\"\n",
    "    print(f\"\\n{status} Q{i+1}: {r['question'][:70]}...\")\n",
    "    print(f\"   Predicted: {r['predicted']}, Correct: {r['correct']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Compare with Original (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Compare with original MedGemma\n",
    "# This requires loading the original model\n",
    "\n",
    "compare_with_original = False  # Set to True if you want to compare\n",
    "\n",
    "if compare_with_original and os.path.exists(ORIGINAL_MODEL):\n",
    "    # Clear memory first\n",
    "    del korean_model\n",
    "    clear_memory()\n",
    "    \n",
    "    print(\"\\nLoading original MedGemma for comparison...\")\n",
    "    \n",
    "    original_model = AutoModelForCausalLM.from_pretrained(\n",
    "        ORIGINAL_MODEL,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    \n",
    "    original_tokenizer = AutoTokenizer.from_pretrained(ORIGINAL_MODEL)\n",
    "    if original_tokenizer.pad_token is None:\n",
    "        original_tokenizer.pad_token = original_tokenizer.eos_token\n",
    "    \n",
    "    original_model.eval()\n",
    "    \n",
    "    original_accuracy, original_results = evaluate_model(\n",
    "        original_model,\n",
    "        original_tokenizer,\n",
    "        english_medical_questions,\n",
    "        \"Original MedGemma\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nOriginal MedGemma accuracy: {original_accuracy:.1f}%\")\n",
    "    print(f\"Korean-adapted accuracy: {korean_accuracy:.1f}%\")\n",
    "    print(f\"Retention: {korean_accuracy / original_accuracy * 100:.1f}%\")\n",
    "else:\n",
    "    print(\"\\nSkipping comparison with original model\")\n",
    "    original_accuracy = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Qualitative English Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test open-ended English questions\n",
    "# Reload Korean model if it was deleted for comparison\n",
    "if 'korean_model' not in dir():\n",
    "    korean_model = AutoModelForCausalLM.from_pretrained(\n",
    "        KOREAN_MODEL_DIR,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    korean_model.eval()\n",
    "\n",
    "english_open_questions = [\n",
    "    \"What are the main symptoms of COVID-19?\",\n",
    "    \"How does hypertension affect the cardiovascular system?\",\n",
    "    \"What lifestyle changes can help manage Type 2 Diabetes?\",\n",
    "]\n",
    "\n",
    "print(\"\\nQualitative English evaluation:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for question in english_open_questions:\n",
    "    prompt = f\"\"\"<|im_start|>system\n",
    "You are a medical AI assistant.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "{question}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "    \n",
    "    inputs = korean_tokenizer(prompt, return_tensors=\"pt\").to(korean_model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = korean_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=korean_tokenizer.pad_token_id,\n",
    "        )\n",
    "    \n",
    "    response = korean_tokenizer.decode(\n",
    "        outputs[0][inputs[\"input_ids\"].shape[1]:],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(f\"A: {response[:400]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save English evaluation results\n",
    "english_eval_results = {\n",
    "    \"model\": KOREAN_MODEL_DIR,\n",
    "    \"benchmark\": \"English Medical QA (Custom)\",\n",
    "    \"korean_model_accuracy\": korean_accuracy,\n",
    "    \"original_model_accuracy\": original_accuracy,\n",
    "    \"retention_rate\": korean_accuracy / original_accuracy * 100 if original_accuracy else None,\n",
    "    \"total_questions\": len(english_medical_questions),\n",
    "    \"results\": korean_results,\n",
    "}\n",
    "\n",
    "results_path = f\"{RESULTS_DIR}/english_retention_eval.json\"\n",
    "with open(results_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(english_eval_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"English Retention Evaluation Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nKorean-adapted model English accuracy: {korean_accuracy:.1f}%\")\n",
    "if original_accuracy:\n",
    "    print(f\"Original model English accuracy: {original_accuracy:.1f}%\")\n",
    "    retention = korean_accuracy / original_accuracy * 100\n",
    "    print(f\"Retention rate: {retention:.1f}%\")\n",
    "print(f\"\\nResults saved to: {results_path}\")\n",
    "print(\"\\nPhase 5 Complete!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  Run phase6_deployment/01_quantize_awq.ipynb for deployment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}